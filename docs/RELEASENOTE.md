# MindSpeed 版本说明书
-   [MindSpeed 1.0](#FrameworkPTAdapter-5-0-RC1md)
    -   [用户须知](#用户须知md)
    -   [新增特性](#新增特性md)
    -   [特性修改](#特性修改md)
    -   [已修复问题](#已修复问题md)
    -   [已知问题](#已知问题md)
    -   [兼容性](#兼容性md)


## MindSpeed 1.0

### 用户须知

本框架基于NVIDIA主导的开源Megatron进行修改，采用插件化适配方式，延续原生的Megatron特性，使用NPU进行大模型加速训练；代码重用性好，支持现有的网络只修改设备类型或数据类型，即可迁移到NPU上使用。使能客户大模型业务快速迁移至昇腾设备，并且支持昇腾专有算法。

### 新增特性

**表 1** MindSpeed支持的版本特性列表

| 一级特性           | 二级特性 |   说明 |
| -------------- | ---------------  | ---------------  |
| Megatron原生特性     |   数据并行 | 支持数据并行训练策略 |
|      |   张量并行 | 支持张量并行训练策略 |
|      |   流水并行 | 支持流水并行训练策略 |
|      |   张量并行 | 支持张量并行训练策略 |
|      |   虚拟流水并行 | 支持虚拟流水并行训练策略 |
|      |   序列并行 | 支持序列并行训练策略 |
|      |   重计算 | 支持选择性重计算和完全重计算策略 |
|      |   分布式优化器 | 支持分布式优化器策略，将优化器状态拆分到所有DP组间 |
|      |   异步DDP | 支持异步DDP，在进行梯度更新时，将数据并行组中的通信和计算并行执行 |
| 昇腾专有算法     |   TP 重计算通信优化 | 重计算通信算子消除，优化重计算层划分，实现大模型训练通信性能提升 |
|      |   内存碎片优化 | 通过对不同生命周期的tensor进行分别管理，以减少内存碎片 |
|      |   自适应选择重计算 | 支持通过自动调整训练内存大小来自动选择重新计算策略 |
|      |   计算通信并行优化 | 通过将计算和通信任务分别拆分成更细粒度的子任务来实现相互的流水掩盖 |
| 昇腾自定义算子     |   npu_dropout_add_layer_norm | 支持自定义算子npu_dropout_add_layer_norm调用 |

### 特性修改

不涉及

### 已修复问题

不涉及

### 已知问题

| 已知问题           | 问题描述 |
| -------------- | ---------------  |

### 兼容性

A800-9010：CentOS 7.6/Ubuntu 18.04, 2.04/BC-Linux 7.6/Debian 9.9/Debian 10/OpenEuler 20.03 LTS

A800-9000：CentOS 7.6/Ubuntu 18.04, 2.04/Euler 2.8, 2.10/Kylin v10/BC-Linux 7.6/OpenEuler 20.03 LTS/UOS 20 1020e